{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ad2abfe",
   "metadata": {},
   "source": [
    "### Interacting with the LLM\n",
    "\n",
    "In this section, we define the model and input message to interact with the LLM. The steps are as follows:\n",
    "\n",
    "1. **Define the Model**: Specify the version of the LLM to use (`llama3.2:latest`).\n",
    "2. **Prepare the Input**: Create a sample text (`'hello llama!'`) and format it as a message for the LLM.\n",
    "3. **Interact with the LLM**: Use the `chat` function from the `ollama` library to send the input message to the specified model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83387be9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatResponse(model='llama3.2:latest', created_at='2025-07-03T06:40:29.398771Z', done=True, done_reason='stop', total_duration=10270369958, load_duration=172937041, prompt_eval_count=28, prompt_eval_duration=4488833250, eval_count=51, eval_duration=5601399541, message=Message(role='assistant', content=\"Hello there, friend! *neighs* How are you doing today? Would you like to chat about something in particular or just shoot the breeze? I'm all ears (or should I say, all nostrils?) and ready to listen!\", images=None, tool_calls=None))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ollama import chat\n",
    "\n",
    "# Define the model to use and the input message\n",
    "model = 'llama3.2:latest'  # Specify the LLM model version\n",
    "sample_text = 'hello llama!'  # Input text to send to the LLM\n",
    "messages = [{'role': 'user', 'content': sample_text}]  # Format the input as a message for the LLM\n",
    "\n",
    "# Interact with the LLM using the chat function\n",
    "response = chat(model=model, messages=messages)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64805946",
   "metadata": {},
   "source": [
    "### Extracting Relevant Information from the Response\n",
    "\n",
    "The `response` variable contains detailed metadata about the interaction with the LLM, including the model used, timestamps, evaluation details, and the assistant's reply. However, for our purposes, we are only interested in the `content` section of the `message` field, which contains the actual response text from the LLM. This is the part that holds the assistant's reply to the input message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336b8dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello there, friend! *neighs* How are you doing today? Would you like to chat about something in particular or just shoot the breeze? I'm all ears (or should I say, all nostrils?) and ready to listen!\n"
     ]
    }
   ],
   "source": [
    "output = response.message.content\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b5215a",
   "metadata": {},
   "source": [
    "### Summarising Text with LLM Prompting\n",
    "\n",
    "In the following section, we will demonstrate how to use LLM prompting to summarize a piece of text. By leveraging a predefined prompt template, we will interact with the LLM to extract a concise summary of the main idea or theme of the provided text. This process showcases the utility of LLMs in text summarization tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce8c7d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Read the following text carefully:\n",
      "\n",
      "START OF TEXT\n",
      "My heart burns with an eternal flame for you!\n",
      "END OF TEXT\n",
      "\n",
      "Return the key theme of the post. Return nothing else but the key theme\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define a template for summarizing text with placeholders for dynamic content\n",
    "template = \"\"\"\n",
    "Read the following text carefully:\n",
    "\n",
    "START OF TEXT\n",
    "{text}\n",
    "END OF TEXT\n",
    "\n",
    "Return the key theme of the post. Return nothing else but the key theme\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Define the sample text to be summarized\n",
    "sample_text = \"My heart burns with an eternal flame for you!\"\n",
    "\n",
    "# Format the template with the sample text to create the final prompt\n",
    "prompt = template.format(text=sample_text)\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d373a496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Love/Passion\n"
     ]
    }
   ],
   "source": [
    "messages = [{'role': 'user', 'content': prompt}]  # Format the input as a message for the LLM\n",
    "response = chat(model=model, messages=messages)\n",
    "output = response.message.content\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64090614",
   "metadata": {},
   "source": [
    "### Implementing LLM Summarization Workflow on a Sample Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "daea0a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My heart burns with an eternal flame for you!\n",
      "You are the sun, the moon, and every star that ever shone!\n",
      "I am hopelessly, wildly, gloriously in love with you!\n",
      "Your name is etched upon the walls of my soul!\n",
      "You have bewitched me, body and soul!\n",
      "I would cross oceans of fire just to see you smile!\n",
      "Every breath I take is a love letter to you!\n",
      "You are my destiny, my downfall, my everything!\n",
      "Without you, even the stars seem dim and lifeless!\n",
      "My love for you defies time, space, and all reason!\n"
     ]
    }
   ],
   "source": [
    "# load dataset \n",
    "with open('sample.txt', 'r', encoding='utf-8') as file:\n",
    "    texts = [line.strip() for line in file]\n",
    "\n",
    "for text in texts:\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbaec554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store the summaries\n",
    "summaries = []\n",
    "\n",
    "# Iterate over each text in the dataset\n",
    "for text in texts:\n",
    "    # Format the prompt template with the current text\n",
    "    prompt = template.format(text=text)\n",
    "    \n",
    "    # Prepare the input message for the LLM\n",
    "    messages = [{'role': 'user', 'content': prompt}]\n",
    "    \n",
    "    # Interact with the LLM to get the response\n",
    "    response = chat(model=model, messages=messages)\n",
    "    \n",
    "    # Extract the summary (key theme) from the response\n",
    "    summary = response.message.content\n",
    "    \n",
    "    # Append the summary to the list of summaries\n",
    "    summaries.append(summary)\n",
    "\n",
    "# save summaries to text file\n",
    "with open('summaries.txt', 'w') as f:\n",
    "    for summary in summaries:\n",
    "        f.write(f\"{summary}\\n\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "792c2f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('summaries.txt', 'r', encoding='utf-8') as file:\n",
    "    summaries = [line.strip() for line in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b57077b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My heart burns with an eternal flame for you! --> Love/Obsession\n",
      "You are the sun, the moon, and every star that ever shone! --> Glory/Adoration\n",
      "I am hopelessly, wildly, gloriously in love with you! --> Love\n",
      "Your name is etched upon the walls of my soul! --> Poetry/Romance\n",
      "You have bewitched me, body and soul! --> Love\n",
      "I would cross oceans of fire just to see you smile! --> Love\n",
      "Every breath I take is a love letter to you! --> Love\n",
      "You are my destiny, my downfall, my everything! --> Destiny\n",
      "Without you, even the stars seem dim and lifeless! --> Adoration or appreciation for a person or relationship\n",
      "My love for you defies time, space, and all reason! --> Love\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(summaries)):\n",
    "    print(f'{texts[i]} --> {summaries[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10f1e1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sicss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
